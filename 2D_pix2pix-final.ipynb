{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nibabel as nib\n",
    "from matplotlib import pyplot as plt\n",
    "import pydicom\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import pandas as pd\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "import albumentations as A\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdTransform(object):\n",
    "    def __init__(self, thr_255):\n",
    "        self.thr = thr_255 / 255.\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return (x>self.thr).to(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fMc2KEKY2dR"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((256,256)),\n",
    "                    #transforms.Normalize([0.5],[0.5]),\n",
    "                    #ThresholdTransform(thr_255=-1)\n",
    "])\n",
    "\n",
    "transform_info = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NORM(array):\n",
    "    new_array = ((array / 65535) * 2) - 1\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, o_path, t_path):\n",
    "        self.o_dataset = []\n",
    "        self.t_dataset = []\n",
    "        self.info_list = []\n",
    "        self.o_path = o_path\n",
    "        self.t_path = t_path\n",
    "\n",
    "    def preprocess(self):     \n",
    "        org_patients = []\n",
    "        \n",
    "        data = pd.read_csv('train_info.csv')\n",
    "        data.set_index('SubjectID', inplace=True)\n",
    "        \n",
    "        \n",
    "        ########### ORIGINAL ###########\n",
    "        # Reading and putting in Original Images\n",
    "        for org_file in glob.glob(self.o_path):\n",
    "            org_patient = []\n",
    "            org_dcm = []\n",
    "            info_list = []\n",
    "            org_name = org_file[31:]\n",
    "            org_patients.append(org_name)\n",
    "            \n",
    "            # DICOM file path\n",
    "            for dcm_file in glob.glob(org_file + '/*'):\n",
    "                dcm_base = os.path.basename(dcm_file)\n",
    "                org_dcm.append(dcm_base)\n",
    "            org_dcm.sort()\n",
    "            \n",
    "            \n",
    "            # DICOM file name\n",
    "            for dcm_name in org_dcm:\n",
    "                org_img = pydicom.dcmread(org_file + '/' + dcm_name)            \n",
    "                \n",
    "                # convert dicom file to numpy array\n",
    "                data1 = org_img.pixel_array\n",
    "                data1 = data1.astype('float32')\n",
    "                np.set_printoptions(edgeitems=200)\n",
    "                \n",
    "                # normalize data\n",
    "                data1 = NORM(data1)\n",
    "                \n",
    "                # change to tensor and resize data to 256x256\n",
    "                data1 = transform(data1)\n",
    "                data1 = np.reshape(data1, (1,1,256,256))\n",
    "                org_patient.append(data1)\n",
    "                \n",
    "            org_output = org_patient[0]\n",
    "\n",
    "            count = 0\n",
    "            for o_data in org_patient:\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                org_output = torch.cat([org_output, o_data], 0)\n",
    "\n",
    "            self.o_dataset.append(org_output)\n",
    "            \n",
    "            \n",
    "        ###### TARGET ##########\n",
    "        \n",
    "        for target_name in org_patients:\n",
    "            tar_patient = []\n",
    "            tar_dcm = []\n",
    "            info_temp = []\n",
    "            \n",
    "            for dcm_file in glob.glob(self.t_path + target_name + '/*'):\n",
    "                dcm_base = os.path.basename(dcm_file)\n",
    "                tar_dcm.append(dcm_base)\n",
    "            tar_dcm.sort()\n",
    "            \n",
    "            for dcm_name in tar_dcm:\n",
    "                tar_img = pydicom.dcmread(self.t_path + target_name + '/' + dcm_name)\n",
    "                \n",
    "                # convert dicom file to numpy array\n",
    "                data2 = tar_img.pixel_array\n",
    "                data2 = data2.astype('float32')\n",
    "                data2 = NORM(data2)\n",
    "                data2 = transform(data2)\n",
    "                data2 = np.reshape(data2, (1,1,256,256))\n",
    "                tar_patient.append(data2)\n",
    "                \n",
    "                target_id = target_name[5:]\n",
    "                info = data.loc[target_id]\n",
    "                info_np = info.to_numpy()\n",
    "                info_torch = torch.Tensor(info_np)\n",
    "                info_torch = info_torch.type(torch.float32)\n",
    "                info_torch = info_torch.reshape(1,1,5)\n",
    "                info_temp.append(info_torch)\n",
    "        \n",
    "            tar_output = tar_patient[0]\n",
    "            info_output = info_temp[0]\n",
    "            \n",
    "            count = 0\n",
    "            for t_data in tar_patient:\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                tar_output = torch.cat([tar_output, t_data], 0)\n",
    "            \n",
    "            self.t_dataset.append(tar_output)\n",
    "            \n",
    "            count = 0\n",
    "            for info in info_temp:\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                info_output = torch.cat([info_output, info], 0)\n",
    "            \n",
    "            self.info_list.append(info_output)\n",
    "            \n",
    "        final_orig = self.o_dataset[0]\n",
    "        final_target = self.t_dataset[0]\n",
    "        final_info = self.info_list[0]\n",
    "        \n",
    "        for i in range(1, len(self.o_dataset)):\n",
    "            final_orig = torch.cat([final_orig, self.o_dataset[i]], 0)\n",
    "            final_target = torch.cat([final_target, self.t_dataset[i]], 0)\n",
    "            final_info = torch.cat([final_info, self.info_list[i]], 0)\n",
    "            \n",
    "        return final_orig, final_target, final_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOiiU4acWqf_",
    "outputId": "62853586-ae48-4bf0-880c-6ba63de698cb"
   },
   "outputs": [],
   "source": [
    "data = Dataloader('/home/mri-any/GAN_Data/orignal/*', '/home/mri-any/GAN_Data/target/')\n",
    "\n",
    "orig, target, info = data.preprocess()\n",
    "print(orig.shape)\n",
    "print(info.shape)\n",
    "ds = TensorDataset(orig, target, info)\n",
    "train_dataloader = DataLoader(ds, batch_size=1, shuffle=True)\n",
    "#train_dataloader = DataLoader(ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Dataloader('/home/mri-any/GAN_test/orignal/*', '/home/mri-any/GAN_test/target/')\n",
    "orig, target, info = test_data.preprocess()\n",
    "print(orig.shape)\n",
    "print(info.shape)\n",
    "\n",
    "ds = TensorDataset(orig, target, info)\n",
    "test_dataloader = DataLoader(ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generator Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PROu4niRb7gQ"
   },
   "outputs": [],
   "source": [
    "# UNet\n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1, bias=False)]\n",
    "\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels)),\n",
    "\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.down = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAluLp3Ee_SB"
   },
   "outputs": [],
   "source": [
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels,4,2,1,bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        ]\n",
    "\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.up = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x,skip):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat((x,skip),1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wvFnCh6ge_z4",
    "outputId": "044e5241-0faf-4664-ddd5-253ea0377139"
   },
   "outputs": [],
   "source": [
    "# generator: 가짜 이미지를 생성합니다.\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.info = info\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64,128)                 \n",
    "        self.down3 = UNetDown(128,256)               \n",
    "        self.down4 = UNetDown(256,512,dropout=0.5) \n",
    "        self.down5 = UNetDown(512,512,dropout=0.5)      \n",
    "        self.down6 = UNetDown(512,512,dropout=0.5)             \n",
    "        self.down7 = UNetDown(512,512,dropout=0.5)              \n",
    "        self.down8 = UNetDown(512,509,normalize=False,dropout=0.5)\n",
    "\n",
    "        self.up1 = UNetUp(512,512,dropout=0.5)\n",
    "        self.up2 = UNetUp(1024,512,dropout=0.5)\n",
    "        self.up3 = UNetUp(1024,512,dropout=0.5)\n",
    "        self.up4 = UNetUp(1024,512,dropout=0.5)\n",
    "        self.up5 = UNetUp(1024,256)\n",
    "        self.up6 = UNetUp(512,128)\n",
    "        self.up7 = UNetUp(256,64)\n",
    "        self.up8 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,1,4,stride=2,padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, info):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        \n",
    "        #print(d8.shape)\n",
    "        d8 = torch.cat([d8, info], 1)\n",
    "        \n",
    "        u1 = self.up1(d8,d7)\n",
    "        u2 = self.up2(u1,d6)\n",
    "        u3 = self.up3(u2,d5)\n",
    "        u4 = self.up4(u3,d4)\n",
    "        u5 = self.up5(u4,d3)\n",
    "        u6 = self.up6(u5,d2)\n",
    "        u7 = self.up7(u6,d1)\n",
    "        u8 = self.up8(u7)\n",
    "\n",
    "        return u8\n",
    "\n",
    "\n",
    "\n",
    "# check\n",
    "\n",
    "# info = torch.randn(150,3,1,1, device=device)\n",
    "# x = torch.randn(150, 1,256,256,device=device)\n",
    "# model = GeneratorUNet().to(device)\n",
    "# out = model(x, info)\n",
    "# print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(5, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), \n",
    "            nn.ReLU(True), nn.Linear(12, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Load Pretrained Encoder Weights\n",
    "encoder_model = encoder()\n",
    "weights = torch.load('./encoder_weight3.pth')\n",
    "encoder_model.load_state_dict(weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrxKnOrJfCvI"
   },
   "outputs": [],
   "source": [
    "class Dis_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "    \n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHhCEMTzfFNP"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage_1 = Dis_block(in_channels*2,64,normalize=False)\n",
    "        self.stage_2 = Dis_block(64, 128)\n",
    "        self.stage_3 = Dis_block(128, 256)\n",
    "        self.stage_4 = Dis_block(256, 512)\n",
    "        self.fc1 = torch.nn.Linear(131072, 2)\n",
    "\n",
    "    def forward(self,a,b):\n",
    "        x = torch.cat((a,b),1)\n",
    "        x = self.stage_1(x)\n",
    "        x = self.stage_2(x)\n",
    "        x = self.stage_3(x)\n",
    "        x = self.stage_4(x)\n",
    "        x = torch.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# check\n",
    "#x = torch.randn(160,1,256,256,device=device)\n",
    "#model = Discriminator().to(device)\n",
    "#out = model(x,x)\n",
    "#print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJGNC8yCfJyn"
   },
   "outputs": [],
   "source": [
    "model_gen = GeneratorUNet().to(device)\n",
    "model_dis = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e03DRW9GfMsf"
   },
   "outputs": [],
   "source": [
    "# 가중치 초기화\n",
    "def initialize_weights(model):\n",
    "    class_name = model.__class__.__name__\n",
    "    if class_name.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "# 가중치 초기화 적용\n",
    "model_gen.apply(initialize_weights);\n",
    "model_dis.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = A.Compose([\n",
    "  A.HorizontalFlip(p=0.5),\n",
    "  A.VerticalFlip(p=0.5),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HfHbcBefOlv"
   },
   "outputs": [],
   "source": [
    "# 손실함수\n",
    "loss_func_gan = nn.BCEWithLogitsLoss()\n",
    "loss_func_pix = nn.L1Loss()\n",
    "\n",
    "# loss_func_pix 가중치\n",
    "lambda_pixel = 100\n",
    "lambda_gen = 1\n",
    "\n",
    "# 최적화 파라미터\n",
    "from torch import optim\n",
    "g_lr = 2e-4\n",
    "d_lr = 2e-8\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "opt_dis = optim.Adam(model_dis.parameters(),lr=d_lr,betas=(beta1,beta2))\n",
    "opt_gen = optim.Adam(model_gen.parameters(),lr=g_lr,betas=(beta1,beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVTvu6B6fRMf",
    "outputId": "4d69379e-893e-4d55-c3ed-fb5b1eaf7963"
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "model_gen.train()\n",
    "model_dis.train()\n",
    "\n",
    "batch_count = 0\n",
    "num_epochs = 100\n",
    "start_time = time.time()\n",
    "\n",
    "loss_hist = {'gen':[],\n",
    "             'dis':[]}\n",
    "\n",
    "epoch_g_loss = []\n",
    "epoch_d_loss = []\n",
    "\n",
    "train_ssim_FO = [] #fake, original\n",
    "train_ssim_FT = [] #fake, target\n",
    "train_ssim_OT = []\n",
    "test_ssim_FO = []\n",
    "test_ssim_FT = []\n",
    "test_ssim_OT = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_ssim_1 = [] #fake, original\n",
    "    train_ssim_2 = [] #fake, target\n",
    "    train_ssim_3 = [] #original, target\n",
    "    \n",
    "    for a, b, info in train_dataloader:\n",
    "        ba_si = a.size(0)\n",
    "        # real image\n",
    "        \n",
    "        \n",
    "#         #### For Augmentation of Data ####\n",
    "#         real_a = a\n",
    "#         real_b = b\n",
    "#         torch.set_printoptions(profile = 'full')\n",
    "               \n",
    "            \n",
    "#         concat_image = torch.cat([real_a, real_b], 0)\n",
    "#         concat_image = concat_image.numpy()\n",
    "#         concat_image = augmentation(image=concat_image)\n",
    "\n",
    "#         #plt.imshow(np.reshape(concat_image['image'][0], (256,256)))\n",
    "#         #plt.imshow(np.reshape(concat_image['image'][1], (256,256)))\n",
    "        \n",
    "        \n",
    "#         real_a = np.reshape(concat_image['image'][0],(1,1,256,256))\n",
    "#         real_b = np.reshape(concat_image['image'][1],(1,1,256,256))\n",
    "        \n",
    "#         real_a = torch.Tensor(real_a)\n",
    "#         real_b = torch.Tensor(real_b)\n",
    "                \n",
    "#         real_a = real_a.to(device)\n",
    "#         real_b = real_b.to(device)\n",
    "        \n",
    "        \n",
    "        real_a = a.to(device)\n",
    "        real_b = b.to(device)\n",
    "        \n",
    "        \n",
    "        ## Labeling for real and fake\n",
    "        real_label = torch.ones(2)\n",
    "        fake_label = torch.zeros(2)\n",
    "        real_label[1] = 0\n",
    "        fake_label[1] = 1\n",
    "        \n",
    "        \n",
    "        real_label, fake_label = real_label.to(device), fake_label.to(device)\n",
    "\n",
    "        ##### GENERATOR #####\n",
    "        model_gen.train()\n",
    "        model_dis.eval()\n",
    "        model_gen.zero_grad()\n",
    "        \n",
    "        \n",
    "        encoded_info = encoder_model(info).to(device)\n",
    "        encoded_info = encoded_info.reshape(1,3,1,1)\n",
    "        \n",
    "\n",
    "        fake_b = model_gen(real_a, encoded_info) # 가짜 이미지 생성\n",
    "        out_dis = model_dis(fake_b, real_b) # 가짜 이미지 \n",
    "        \n",
    "        gen_loss = loss_func_gan(out_dis, real_label)\n",
    "        pixel_loss = loss_func_pix(fake_b, real_b)\n",
    "\n",
    "        \n",
    "        g_loss = (lambda_gen * gen_loss) + (lambda_pixel * pixel_loss)\n",
    "        g_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "       \n",
    "        ##### DISCRIMINATOR #######\n",
    "        model_dis.train()\n",
    "        model_dis.zero_grad()\n",
    "\n",
    "        out_dis = model_dis(real_b, real_a) # 진짜 이미지 식별\n",
    "        real_loss = loss_func_gan(out_dis, real_label)\n",
    "\n",
    "        out_dis = model_dis(fake_b.detach(), real_a) # 가짜 이미지 식별\n",
    "        fake_loss = loss_func_gan(out_dis, fake_label)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss) / 2.\n",
    "        d_loss.backward()\n",
    "        opt_dis.step()\n",
    "        \n",
    "        epoch_g_loss.append(g_loss.item())\n",
    "        epoch_d_loss.append(d_loss.item())\n",
    "        \n",
    "        \n",
    "        #### TRAINING SET SSIM ####\n",
    "        fake_imgs = model_gen(a.to(device), encoded_info).detach().cpu()\n",
    "        fake_imgs = np.squeeze(fake_imgs[0])\n",
    "\n",
    "        real_imgs_a = a\n",
    "        real_imgs_a = np.squeeze(real_imgs_a[0])\n",
    "        real_imgs_b = b\n",
    "        real_imgs_b = np.squeeze(real_imgs_b[0])\n",
    "\n",
    "\n",
    "        fake_np = fake_imgs.numpy()\n",
    "        real_np_a = real_imgs_a.numpy()\n",
    "        real_np_b = real_imgs_b.numpy()\n",
    "\n",
    "        s1 = ssim(fake_np, real_np_a)\n",
    "        s2 = ssim(fake_np, real_np_b)\n",
    "        s3 = ssim(real_np_a, real_np_b)\n",
    "        \n",
    "        train_ssim_1.append(s1) #fake, original\n",
    "        train_ssim_2.append(s2) #fake, target\n",
    "        train_ssim_3.append(s3) #original, target\n",
    "        ##############################\n",
    "            \n",
    "        \n",
    "        batch_count +=1\n",
    "        \n",
    "        if batch_count % 6516 == 0:\n",
    "            loss_hist['gen'].append(sum(epoch_g_loss)/len(epoch_g_loss))\n",
    "            loss_hist['dis'].append(sum(epoch_d_loss)/len(epoch_d_loss))\n",
    "            epoch_g_loss = []\n",
    "            epoch_d_loss = []\n",
    "            train_ssim_FO.append(sum(train_ssim_1)/len(train_ssim_1))\n",
    "            train_ssim_FT.append(sum(train_ssim_2)/len(train_ssim_2))\n",
    "            train_ssim_OT.append(sum(train_ssim_3)/len(train_ssim_3))\n",
    "            \n",
    "#             print(\"FO:\",sum(train_ssim_1)/len(train_ssim_1))\n",
    "#             print(\"FT:\",sum(train_ssim_2)/len(train_ssim_2))\n",
    "#             print(\"OT:\",sum(train_ssim_3)/len(train_ssim_3))\n",
    "            \n",
    "        \n",
    "        \n",
    "        if batch_count % 6516 == 0:\n",
    "            print('Epoch: %.0f, G_Loss: %.6f, D_Loss: %.6f, time: %.2f min' %(epoch, g_loss.item(), d_loss.item(), (time.time()-start_time)/60))\n",
    "            fake_imgs = model_gen(a.to(device), encoded_info).detach().cpu()\n",
    "            real_imgs = (b.to(device)).detach().cpu()\n",
    "\n",
    "            a = np.squeeze(a)\n",
    "            real_imgs = np.squeeze(real_imgs)\n",
    "            fake_imgs = np.squeeze(fake_imgs)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_subplot(1,3,1)\n",
    "            ax2 = fig.add_subplot(1,3,2)\n",
    "            ax3 = fig.add_subplot(1,3,3)\n",
    "\n",
    "            ax1.imshow(a)\n",
    "            ax2.imshow(fake_imgs)\n",
    "            ax3.imshow(real_imgs)\n",
    "            plt.show()\n",
    "\n",
    "            # Saving model weights\n",
    "            path2models = '/home/mri-any/GAN_weight/test/'\n",
    "            os.makedirs(path2models, exist_ok=True)\n",
    "\n",
    "            gen_weight_path = 'weights_gen_' + str(epoch) + '.pt'\n",
    "            dis_weight_path = 'weights_dis_' + str(epoch) + '.pt'\n",
    "            path2weights_gen = os.path.join(path2models, gen_weight_path)\n",
    "            path2weights_dis = os.path.join(path2models, dis_weight_path)\n",
    "\n",
    "            torch.save(model_gen.state_dict(), path2weights_gen)\n",
    "            torch.save(model_dis.state_dict(), path2weights_dis)\n",
    "\n",
    "            \n",
    "            #### TESTING SET SSIM #### \n",
    "            model_gen.eval()\n",
    "\n",
    "            ssim_1 = [] #fake, original\n",
    "            ssim_2 = [] #fake, target\n",
    "            ssim_3 = [] #original, target\n",
    "\n",
    "            \n",
    "    \n",
    "            for a,b, info in test_dataloader:\n",
    "                encoded_info = encoder_model(info).to(device)\n",
    "                encoded_info = encoded_info.reshape(1,3,1,1)\n",
    "\n",
    "                fake_imgs = model_gen(a.to(device), encoded_info).detach().cpu()\n",
    "                fake_imgs = np.squeeze(fake_imgs[0])\n",
    "                real_imgs_a = a\n",
    "                real_imgs_a = np.squeeze(real_imgs_a[0])\n",
    "                real_imgs_b = b\n",
    "                real_imgs_b = np.squeeze(real_imgs_b[0])\n",
    "\n",
    "                fake_np = fake_imgs.numpy()\n",
    "                real_a_np = real_imgs_a.numpy()\n",
    "                real_b_np = real_imgs_b.numpy()\n",
    "\n",
    "                s1 = ssim(fake_np, real_a_np) #fake, original\n",
    "                ssim_1.append(s1)\n",
    "\n",
    "                s2 = ssim(fake_np, real_b_np) #fake, target\n",
    "                ssim_2.append(s2)\n",
    "\n",
    "                s3 = ssim(real_a_np, real_b_np) #original, target\n",
    "                ssim_3.append(s3)\n",
    "\n",
    "\n",
    "        \n",
    "            test_ssim_FO.append(sum(ssim_1) / len(ssim_1))\n",
    "            test_ssim_FT.append(sum(ssim_2) / len(ssim_2))\n",
    "            test_ssim_OT.append(sum(ssim_3) / len(ssim_3))\n",
    "\n",
    "            print('fake, original = ', (sum(ssim_1) / len(ssim_1)))\n",
    "            print('fake, target = ', (sum(ssim_2) / len(ssim_2)))\n",
    "            print('original, target = ', (sum(ssim_3) / len(ssim_3)))\n",
    "            #################################\n",
    "            \n",
    "            \n",
    "        del a\n",
    "        del b\n",
    "        del real_label\n",
    "        del fake_label\n",
    "        del encoded_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss history of generator | discriminator | training, testing SSIM \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Loss Progress')\n",
    "plt.plot(loss_hist['gen'], label='Gen. Loss')\n",
    "plt.title('Gen Loss')\n",
    "plt.xlabel('epoch count')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_hist['dis'], label='Dis. Loss')\n",
    "plt.title('Dis Loss')\n",
    "plt.ylim(0,3)\n",
    "plt.xlabel('epoch count')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_ssim_FO, label='train_FO')\n",
    "plt.plot(train_ssim_FT, label='train_FT')\n",
    "plt.plot(train_ssim_OT, label='train_OT')\n",
    "plt.plot(test_ssim_FO, label='test_FO')\n",
    "plt.plot(test_ssim_FT, label='test_FT')\n",
    "plt.plot(test_ssim_OT, label='test_OT')\n",
    "plt.title('SSIM')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('epoch count')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2models = '/home/mri-any/GAN_weight/final_migan/'\n",
    "# Call saved model weights\n",
    "path2weights_gen = os.path.join(path2models, 'weights_gen_20.pt')\n",
    "weights = torch.load(path2weights_gen)\n",
    "model_gen.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Dataloader('/home/mri-any/GAN_test/orignal/*', '/home/mri-any/GAN_test/target/')\n",
    "orig, target, info = test_data.preprocess()\n",
    "ds = TensorDataset(orig, target, info)\n",
    "test_dataloader = DataLoader(ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "ssim_1 = [] #fake, original\n",
    "ssim_2 = [] #fake, target\n",
    "ssim_3 = [] #original, target\n",
    "\n",
    "fid_1 = [] #fake, original\n",
    "fid_2 = [] #fake, target\n",
    "fid_3 = [] #original, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation model\n",
    "model_gen.eval()\n",
    "\n",
    "count = 0\n",
    "\n",
    "sum_og = 0\n",
    "sum_ot = 0\n",
    "sum_tg = 0\n",
    "\n",
    "# 가짜 이미지 생성\n",
    "with torch.no_grad():\n",
    "    for a,b, info in test_dataloader:\n",
    "        encoded_info = encoder_model(info).to(device)\n",
    "        encoded_info = encoded_info.reshape(1,3,1,1)\n",
    "        \n",
    "        fake_imgs = model_gen(a.to(device), encoded_info).detach().cpu()\n",
    "        fake_imgs = np.squeeze(fake_imgs[0])\n",
    "        real_imgs_a = a\n",
    "        real_imgs_a = np.squeeze(real_imgs_a[0])\n",
    "        real_imgs_b = b\n",
    "        real_imgs_b = np.squeeze(real_imgs_b[0])\n",
    "        \n",
    "        fake_np = fake_imgs.numpy()\n",
    "        real_a_np = real_imgs_a.numpy()\n",
    "        real_b_np = real_imgs_b.numpy()\n",
    "        \n",
    "        s1 = ssim(fake_np, real_a_np) #fake, original\n",
    "        ssim_1.append(s1)\n",
    "        \n",
    "        s2 = ssim(fake_np, real_b_np) #fake, target\n",
    "        ssim_2.append(s2)\n",
    "        \n",
    "        s3 = ssim(real_a_np, real_b_np) #original, target\n",
    "        ssim_3.append(s3)\n",
    "        \n",
    "        \n",
    "        if count % 300 == 0:\n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_subplot(1,3,1)\n",
    "            ax2 = fig.add_subplot(1,3,2)\n",
    "            ax3 = fig.add_subplot(1,3,3)\n",
    "            ax1.set_title('original: year 1')\n",
    "            ax2.set_title('fake')\n",
    "            ax3.set_title('target: year 3')\n",
    "            ax1.imshow(real_imgs_a, cmap = 'gray')\n",
    "            ax2.imshow(fake_imgs, cmap = 'gray')\n",
    "            ax3.imshow(real_imgs_b, cmap = 'gray')\n",
    "            plt.show()\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "print('fake, original = ', (sum(ssim_1) / len(ssim_1)))\n",
    "print('fake, target = ', (sum(ssim_2) / len(ssim_2)))\n",
    "print('original, target = ', (sum(ssim_3) / len(ssim_3)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2D_pix2pix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
